# ðŸš€ PLAN DE ACCIÃ“N v1.1 - Advanced Document AI Pipeline

**Proyecto:** ETL_ET
**Objetivo:** ConversiÃ³n estructurada + Matching WBS + DeduplicaciÃ³n + Reportes MD
**Stack:** Docling/Marker + sentence-transformers + faiss + Template Excel

---

## ðŸ“Š RESUMEN EJECUTIVO

**Estado Actual (v1.0):**
- âœ… Pipeline bÃ¡sico: PDF â†’ OCR â†’ Parse â†’ Excel (5 hojas)
- âœ… Arquitectura modular (src/ organizado)
- âœ… Pydantic models + structlog
- âœ… Tests bÃ¡sicos (smoke + parse)

**Estado Objetivo (v1.1):**
- âœ… ConversiÃ³n estructurada (Docling/Marker) â†’ ET.md + ET.json
- âœ… Matching semÃ¡ntico WBS â†” ET (embeddings + fuzzy)
- âœ… ExtracciÃ³n de recursos layout-aware
- âœ… ResoluciÃ³n de duplicados automÃ¡tica
- âœ… Outputs: OUT.json + RUN_REPORT.md + rubros_md/*.md
- âœ… Excel por rubro con template
- âœ… CLI extendido (--mode advanced, --reference wbs.xlsx)

---

## ðŸŽ¯ FASES DE IMPLEMENTACIÃ“N

### FASE 0: AUDITORÃA Y SETUP INICIAL

**Objetivo:** Verificar estado actual, preparar estructura, configurar dependencias.

**Tareas:**

- [ ] **0.1** Auditar mÃ³dulos existentes
  - Verificar contratos de `src/pipeline.py` (inputs/outputs)
  - Revisar modelos Pydantic en `src/models/schemas.py`
  - Identificar puntos de extensiÃ³n (legacy vs advanced path)

- [ ] **0.2** Crear estructura de carpetas v1.1
  ```
  src/convert/           # Docling, Marker, PyMuPDF4LLM
  src/outline/           # OUTLINE.md builder
  src/ingest/reference_reader.py  # WBS reference loader
  src/match/             # Embedder, matcher, scoring
  src/dedupe/            # DeduplicaciÃ³n y conflictos
  src/report/            # MD reporters (RUN_REPORT + rubros_md)
  src/export/template_exporter.py
  src/config/settings.py
  data/templates/
  data/artifacts/        # ET.md, ET.json, OUT.json, etc.
  tests/test_convert.py
  tests/test_match.py
  tests/test_dedupe.py
  tests/fixtures/        # PDFs sintÃ©ticos, WBS mock
  ```

- [ ] **0.3** Actualizar requirements.txt
  - Agregar: docling, marker-pdf, pymupdf4llm
  - Agregar: sentence-transformers, faiss-cpu
  - Agregar: openpyxl (ya existe, verificar versiÃ³n)
  - Marcar opcionales: easyocr (ya opcional), torch (para embeddings)
  - Crear requirements-full.txt vs requirements-minimal.txt

- [ ] **0.4** Configurar Settings (Pydantic)
  - Crear `src/config/settings.py`
  - Variables: OCR_LANG, MATCH_THRESHOLD, EXPORT_MODE, ARTIFACT_DIR
  - Cargar desde .env con defaults

**Definition of Done:**
- âœ… Estructura de carpetas creada
- âœ… requirements-full.txt instalable sin errores
- âœ… Settings.py funcional con defaults
- âœ… DocumentaciÃ³n actualizada (Ã¡rbol de carpetas en README)

**Artefactos:**
- `PLAN_V1.1.md` (este archivo)
- `requirements-full.txt`
- `src/config/settings.py`
- Carpetas creadas

---

### FASE 1: INTEGRACIÃ“N CONVERSIÃ“N DOC â†’ (ET.md + ET.json)

**Objetivo:** Integrar Docling/Marker/PyMuPDF4LLM para conversiÃ³n estructurada.

**Tareas:**

- [ ] **1.1** Implementar `src/convert/docling_converter.py`
  - FunciÃ³n: `convert_with_docling(pdf_path: Path) -> ConversionResult`
  - Output: ET.md + ET.json (estructura: secciones, tablas, bloques)
  - Manejar excepciones (PDF corrupto, timeout)
  - Confidence score por pÃ¡gina

- [ ] **1.2** Implementar `src/convert/marker_converter.py`
  - FunciÃ³n: `convert_with_marker(pdf_path: Path) -> ConversionResult`
  - Fallback si Docling falla
  - Output: ET.md + ET.json (formato normalizado)

- [ ] **1.3** Implementar `src/convert/pymupdf_converter.py`
  - FunciÃ³n: `convert_with_pymupdf(pdf_path: Path) -> ConversionResult`
  - Fallback rÃ¡pido (solo MD, JSON mÃ­nimo)
  - Para debugging

- [ ] **1.4** Implementar `src/convert/converter_router.py`
  - FunciÃ³n: `convert_pdf(pdf_path: Path, strategy: str = "auto") -> ConversionResult`
  - Strategy: "docling" | "marker" | "pymupdf" | "auto"
  - Auto: intenta Docling â†’ Marker â†’ PyMuPDF
  - Log de cuÃ¡l conversor se usÃ³ y por quÃ©

- [ ] **1.5** Definir modelo `ConversionResult` (Pydantic)
  ```python
  class ConversionResult(BaseModel):
      md_path: Path
      json_path: Path
      converter_used: Literal["docling", "marker", "pymupdf"]
      pages_processed: int
      confidence: float
      processing_time_ms: float
      warnings: List[str]
  ```

- [ ] **1.6** Integrar en pipeline.py
  - Agregar parÃ¡metro `conversion_strategy: str = "auto"`
  - Si mode="advanced", usar converter_router
  - Guardar artefactos en `data/artifacts/`

**Definition of Done:**
- âœ… 3 conversores implementados con fallbacks
- âœ… Router funcional (auto mode selecciona mejor)
- âœ… ET.md y ET.json generados correctamente
- âœ… Tests unitarios (mock PDFs, verificar outputs)
- âœ… Documentado en SPEC.md secciÃ³n "Advanced Conversion"

**Artefactos:**
- `src/convert/*.py` (4 mÃ³dulos)
- `ConversionResult` en `src/models/schemas.py`
- `tests/test_convert.py`
- ET.md, ET.json en `data/artifacts/`

---

### FASE 2: GENERACIÃ“N DE OUTLINE JERÃRQUICO (OUTLINE.md)

**Objetivo:** Crear OUTLINE.md con estructura: PÃ¡gina â†’ SecciÃ³n â†’ Rubro.

**Tareas:**

- [ ] **2.1** Implementar `src/outline/outline_builder.py`
  - FunciÃ³n: `build_outline(et_json: Path) -> OutlineStructure`
  - Parse ET.json para identificar jerarquÃ­a
  - Detectar cÃ³digos de rubro (XX.XX.XX)
  - Generar Ã¡rbol: PÃ¡gina â†’ SecciÃ³n â†’ SubsecciÃ³n â†’ Rubro

- [ ] **2.2** Implementar `generate_outline_md(outline: OutlineStructure) -> Path`
  - Genera OUTLINE.md con formato:
    ```markdown
    # OUTLINE - Especificaciones TÃ©cnicas

    ## PÃ¡gina 1
    ### SecciÃ³n 1.1: MOVIMIENTO DE TIERRAS
    - 01.01.01 ExcavaciÃ³n manual (lÃ­neas 10-25)
    - 01.01.02 Relleno compactado (lÃ­neas 26-45)

    ## PÃ¡gina 2
    ...
    ```
  - Indicar nÃºmero de lÃ­nea o char_offset para trazabilidad

- [ ] **2.3** Definir modelo `OutlineStructure` (Pydantic)
  ```python
  class OutlineNode(BaseModel):
      level: int  # 1=pÃ¡gina, 2=secciÃ³n, 3=rubro
      title: str
      code: Optional[str]  # Si es rubro
      page: int
      line_start: Optional[int]
      line_end: Optional[int]
      children: List['OutlineNode'] = []
  ```

- [ ] **2.4** Integrar en pipeline avanzado
  - Generar OUTLINE.md despuÃ©s de conversiÃ³n
  - Usar para navegaciÃ³n rÃ¡pida (debugging)

**Definition of Done:**
- âœ… OUTLINE.md generado con jerarquÃ­a clara
- âœ… CÃ³digos de rubro detectados y ubicados
- âœ… Tests: verificar jerarquÃ­a con ET.json mock
- âœ… Documentado en SPEC.md

**Artefactos:**
- `src/outline/outline_builder.py`
- `OutlineStructure` en `src/models/schemas.py`
- OUTLINE.md en `data/artifacts/`
- `tests/test_outline.py`

---

### FASE 3: INGEST WBS REFERENCE + MODELOS

**Objetivo:** Cargar archivo WBS de referencia (XLSX/CSV) y modelar.

**Tareas:**

- [ ] **3.1** Implementar `src/ingest/reference_reader.py`
  - FunciÃ³n: `load_wbs_reference(file_path: Path) -> List[ReferenceRubro]`
  - Soportar XLSX y CSV
  - Columnas esperadas: codigo, descripcion, unidad
  - Columnas opcionales: precio_unitario, cantidad (ignorar)
  - Validar con Pydantic

- [ ] **3.2** Definir modelo `ReferenceRubro` (Pydantic)
  ```python
  class ReferenceRubro(BaseModel):
      wbs_id: str  # Generado: hash o index
      codigo: str
      descripcion: str
      unidad: str
      metadata: Dict[str, Any] = {}  # Campos extra

      @field_validator('codigo')
      def normalize_codigo(cls, v):
          # Normalizar: 01.01.01 vs 1.1.1 â†’ 01.01.01
          return normalize_rubro_code(v)
  ```

- [ ] **3.3** Implementar normalizaciÃ³n de cÃ³digo
  - FunciÃ³n: `normalize_rubro_code(code: str) -> str`
  - Casos:
    - "1.1.1" â†’ "01.01.01"
    - "01-01-01" â†’ "01.01.01"
    - "01 01 01" â†’ "01.01.01"
    - OCR errors: "O1.01.01" â†’ "01.01.01" (Oâ†’0)
  - Usar regex + heurÃ­sticas

- [ ] **3.4** Implementar validaciÃ³n WBS
  - Verificar duplicados en WBS (mismo cÃ³digo)
  - Warning si hay cÃ³digos invÃ¡lidos
  - Generar reporte: `WBS_VALIDATION.md`

**Definition of Done:**
- âœ… WBS cargado desde XLSX/CSV
- âœ… NormalizaciÃ³n de cÃ³digos funcional
- âœ… ValidaciÃ³n de duplicados WBS
- âœ… Tests: cargar fixtures WBS con casos edge
- âœ… Documentado en SPEC.md

**Artefactos:**
- `src/ingest/reference_reader.py`
- `src/utils/text_norm.py` (normalize_rubro_code)
- `ReferenceRubro` en `src/models/schemas.py`
- `tests/test_reference.py`
- `tests/fixtures/wbs_example.xlsx`

---

### FASE 4: MATCHING WBS â†” ET (SEMÃNTICO + FUZZY)

**Objetivo:** Match rubros WBS con rubros detectados en ET usando embeddings + fuzzy.

**Tareas:**

- [ ] **4.1** Implementar `src/match/embedder.py`
  - Modelo: sentence-transformers ("paraphrase-multilingual-MiniLM-L12-v2")
  - FunciÃ³n: `embed_rubros(rubros: List[str]) -> np.ndarray`
  - Cache de embeddings (joblib)
  - Batch processing (para performance)

- [ ] **4.2** Implementar `src/match/matcher.py`
  - FunciÃ³n: `match_wbs_to_et(wbs_rubros, et_rubros, threshold=0.75) -> List[MatchResult]`
  - Estrategia multi-stage:
    1. **Regla dura (cÃ³digo exacto):** Si codigo match â†’ score=1.0
    2. **Fuzzy cÃ³digo:** rapidfuzz (threshold 80) â†’ score=0.9
    3. **Embeddings:** cosine similarity â†’ score variable
    4. **Hybrid:** (fuzzy_desc * 0.3) + (embedding_sim * 0.7)
  - Threshold configurable (default 0.75)

- [ ] **4.3** Implementar FAISS index (opcional, si >1000 rubros)
  - FunciÃ³n: `build_faiss_index(embeddings: np.ndarray) -> faiss.Index`
  - BÃºsqueda k-NN rÃ¡pida
  - Solo si len(et_rubros) > 1000

- [ ] **4.4** Definir modelo `MatchResult` (Pydantic)
  ```python
  class MatchResult(BaseModel):
      wbs_rubro_id: str
      et_rubro_id: Optional[str]
      score: float  # 0.0-1.0
      match_type: Literal["exact_code", "fuzzy_code", "semantic", "hybrid", "unmatched"]
      evidence: MatchEvidence

  class MatchEvidence(BaseModel):
      pages: List[int]
      snippet: str  # Max 500 chars
      code_similarity: Optional[float]
      desc_similarity: Optional[float]
      unit_match: bool
  ```

- [ ] **4.5** Implementar `src/match/scoring.py`
  - FunciÃ³n: `calculate_match_confidence(match: MatchResult) -> float`
  - Penalizar si unidad no coincide
  - Boost si cÃ³digo exacto
  - Threshold para ambiguous (0.65-0.75)

- [ ] **4.6** Categorizar resultados
  - **MATCHED (score >= 0.75):** Aceptado
  - **AMBIGUOUS (0.65-0.75):** Revisar manual
  - **UNMATCHED (< 0.65):** No match encontrado

**Definition of Done:**
- âœ… Embeddings generados y cacheados
- âœ… Matching multi-stage implementado
- âœ… FAISS opcional funcional
- âœ… MatchResult con evidencia completa
- âœ… Tests: casos matched/ambiguous/unmatched
- âœ… Documentado en SPEC.md (secciÃ³n "Matching SemÃ¡ntico")

**Artefactos:**
- `src/match/embedder.py`
- `src/match/matcher.py`
- `src/match/scoring.py`
- `MatchResult` en `src/models/schemas.py`
- `tests/test_match.py`
- Cache embeddings en `data/cache/embeddings/`

---

### FASE 5: EXTRACCIÃ“N DE RECURSOS LAYOUT-AWARE

**Objetivo:** Extraer materiales/equipos desde ET.json usando estructura de tablas/listas.

**Tareas:**

- [ ] **5.1** Implementar `src/parse/resource_extractor.py`
  - FunciÃ³n: `extract_resources_from_json(et_json: Path, rubro_id: str) -> List[Recurso]`
  - Parse tablas en ET.json (si existe secciÃ³n "tables")
  - Parse listas con viÃ±etas/numeraciÃ³n
  - Identificar columnas: nombre, unidad, cantidad
  - Fallback: regex en texto plano (mÃ©todo v1.0)

- [ ] **5.2** ClasificaciÃ³n MATERIAL/EQUIPO mejorada
  - Usar embeddings (opcional) para clasificaciÃ³n
  - Keywords ampliados (30+ por categorÃ­a)
  - Fuzzy matching (rapidfuzz)
  - Confidence score por recurso

- [ ] **5.3** Trazabilidad de recursos
  - Cada recurso debe tener:
    - `pages: List[int]`
    - `snippet: str` (contexto)
    - `table_id: Optional[str]` (si viene de tabla)
    - `confidence: float`

- [ ] **5.4** Integrar con MatchResult
  - Recursos asociados a rubro matched
  - Si rubro no matcheÃ³, recursos quedan "orphan"

**Definition of Done:**
- âœ… ExtracciÃ³n desde tablas funcional
- âœ… ClasificaciÃ³n mejorada con embeddings (opcional)
- âœ… Trazabilidad completa (page + snippet + table_id)
- âœ… Tests: verificar extracciÃ³n desde ET.json mock
- âœ… Documentado en SPEC.md

**Artefactos:**
- `src/parse/resource_extractor.py`
- Tests actualizados en `tests/test_parse.py`
- Fixtures: ET.json con tablas

---

### FASE 6: RESOLUCIÃ“N DE DUPLICADOS Y CONFLICTOS

**Objetivo:** Detectar y resolver rubros duplicados/conflictivos.

**Tareas:**

- [ ] **6.1** Implementar `src/dedupe/dedupe_engine.py`
  - FunciÃ³n: `detect_duplicates(et_rubros: List[ETRubro]) -> List[DuplicateGroup]`
  - Casos:
    1. **Duplicado exacto:** Mismo cÃ³digo, misma unidad â†’ MERGE
    2. **Conflicto:** Mismo cÃ³digo, distinta unidad â†’ SPLIT
    3. **CÃ³digo ausente:** Sin cÃ³digo detectado â†’ HASH_ID

- [ ] **6.2** Estrategia de merge
  - FunciÃ³n: `merge_exact_duplicates(group: DuplicateGroup) -> ETRubro`
  - Unir recursos de ambos rubros
  - Combinar pÃ¡ginas (union)
  - Promedio de confidence
  - Generar provenance: `merged_from: List[str]`

- [ ] **6.3** Estrategia de split
  - FunciÃ³n: `split_conflicts(group: DuplicateGroup) -> List[ETRubro]`
  - Crear cÃ³digos: "01.01.01#A", "01.01.01#B"
  - Marcar con `conflict_flag: True`
  - Incluir ambos en OUT.json

- [ ] **6.4** CÃ³digo ausente (fallback)
  - Generar ID: `HASH_<sha256[:8]>` basado en descripciÃ³n
  - Marcar con `code_missing: True`
  - Incluir en warnings

- [ ] **6.5** Definir modelos
  ```python
  class DuplicateGroup(BaseModel):
      group_id: str
      rubros: List[str]  # IDs de rubros duplicados
      duplicate_type: Literal["exact", "conflict", "code_missing"]
      resolution: Literal["merged", "split", "manual"]

  class ConflictRecord(BaseModel):
      original_code: str
      rubros_conflictivos: List[str]
      reason: str  # "unidad_diferente", "descripcion_diferente"
      resolution: str  # "split_as_A_B"
  ```

**Definition of Done:**
- âœ… Duplicados exactos mergeados automÃ¡ticamente
- âœ… Conflictos splitados con cÃ³digo#A, #B
- âœ… CÃ³digos ausentes con HASH_ID
- âœ… Tests: casos merge/split/hash
- âœ… Documentado en SPEC.md (secciÃ³n "Dedup & Conflicts")

**Artefactos:**
- `src/dedupe/dedupe_engine.py`
- `DuplicateGroup`, `ConflictRecord` en `src/models/schemas.py`
- `tests/test_dedupe.py`

---

### FASE 7: OUT.json + REPORTES MD (RUN_REPORT + rubros_md)

**Objetivo:** Generar outputs finales estructurados.

**Tareas:**

- [ ] **7.1** Definir esquema `OUT.json`
  ```json
  {
    "metadata": {
      "pdf_filename": "ET_ejemplo.pdf",
      "wbs_filename": "WBS_referencia.xlsx",
      "processing_date": "2026-01-28T10:30:00",
      "conversion_strategy": "docling",
      "match_threshold": 0.75
    },
    "summary": {
      "total_wbs_rubros": 150,
      "total_et_rubros": 145,
      "matched": 130,
      "ambiguous": 10,
      "unmatched": 10,
      "duplicates_merged": 5,
      "conflicts_split": 2
    },
    "matches": [
      {
        "wbs_rubro_id": "WBS_001",
        "et_rubro_id": "RUB_01_01_01_P1",
        "score": 0.95,
        "match_type": "exact_code",
        "evidence": {...},
        "recursos": [...]
      }
    ],
    "duplicates": [...],
    "conflicts": [...],
    "warnings": [...]
  }
  ```

- [ ] **7.2** Implementar `src/report/json_generator.py`
  - FunciÃ³n: `generate_out_json(results: PipelineResults) -> Path`
  - Validar con Pydantic antes de guardar
  - Pretty print (indent=2)

- [ ] **7.3** Implementar `src/report/md_reporter.py`
  - FunciÃ³n: `generate_run_report(results: PipelineResults) -> Path`
  - Contenido RUN_REPORT.md:
    ```markdown
    # RUN REPORT - Pipeline v1.1

    **PDF:** ET_ejemplo.pdf
    **WBS:** WBS_referencia.xlsx
    **Fecha:** 2026-01-28 10:30:00

    ## ðŸ“Š Resumen NumÃ©rico
    | MÃ©trica | Valor |
    |---------|-------|
    | Rubros WBS | 150 |
    | Rubros ET | 145 |
    | Matched (âœ…) | 130 |
    | Ambiguous (âš ï¸) | 10 |
    | Unmatched (âŒ) | 10 |

    ## ðŸ”„ Duplicados Resueltos
    | CÃ³digo | Tipo | ResoluciÃ³n |
    |--------|------|------------|
    | 01.01.01 | Exacto | Merged |
    | 02.03.05 | Conflicto | Split (A/B) |

    ## âš ï¸ Conflictos Detectados
    | CÃ³digo | Rubro A | Rubro B | RazÃ³n |
    |--------|---------|---------|-------|
    | 03.02.01 | Unidad: mÂ² | Unidad: mÂ³ | Unidad diferente |

    ## ðŸ”´ Top Warnings
    1. [HIGH] Rubro 05.01.02: CÃ³digo no detectado (PÃ¡gina 15)
    2. [MEDIUM] Rubro 06.03.01: Unidad desconocida "pzs"
    ...
    ```

- [ ] **7.4** Implementar `src/report/rubro_report.py`
  - FunciÃ³n: `generate_rubro_reports(results: PipelineResults) -> Path`
  - Crear `rubros_md/` con un archivo por rubro:
    ```markdown
    # Rubro: 01.01.01 - EXCAVACIÃ“N MANUAL

    ## ðŸŽ¯ Match WBS â†’ ET
    - **WBS ID:** WBS_001
    - **ET ID:** RUB_01_01_01_P1
    - **Score:** 0.95 (Exact Code Match)
    - **Unidad:** mÂ³ âœ…

    ## ðŸ“„ Evidencia
    **PÃ¡ginas:** 5, 6
    **Snippet:**
    ```
    01.01.01 EXCAVACIÃ“N MANUAL EN TERRENO NATURAL
    Unidad: mÂ³

    Se realizarÃ¡ excavaciÃ³n manual...
    (lÃ­neas 1-30)
    ```

    ## ðŸ”§ Recursos ExtraÃ­dos
    | Tipo | Nombre | Unidad | Cantidad |
    |------|--------|--------|----------|
    | MATERIAL | Arena gruesa | mÂ³ | 0.5 |
    | EQUIPO | Herramientas manuales | % | 3.0 |

    ## âš ï¸ Warnings
    - [LOW] Recurso "Agua" sin unidad especificada
    ```

- [ ] **7.5** Limitar tamaÃ±o de reportes
  - Snippet mÃ¡ximo: 30 lÃ­neas (truncar si excede)
  - Recursos: mÃ¡ximo 50 por rubro (truncar + warning)
  - RUN_REPORT: mÃ¡ximo 2 pantallas (resumir si excede)

**Definition of Done:**
- âœ… OUT.json generado y validado
- âœ… RUN_REPORT.md con resumen + tablas
- âœ… rubros_md/*.md (1 por rubro)
- âœ… TamaÃ±os limitados (legible)
- âœ… Tests: verificar formato y contenido
- âœ… Documentado en SPEC.md

**Artefactos:**
- `src/report/json_generator.py`
- `src/report/md_reporter.py`
- `src/report/rubro_report.py`
- OUT.json, RUN_REPORT.md, rubros_md/ en `data/artifacts/`
- `tests/test_report.py`

---

### FASE 8: EXPORT EXCEL POR RUBRO CON TEMPLATE

**Objetivo:** Generar Excel con 1 hoja por rubro (modo per-rubro) o hojas globales (fallback).

**Tareas:**

- [ ] **8.1** Crear template default
  - Archivo: `data/templates/rubro_template.xlsx`
  - Estructura de hoja:
    ```
    [Header]
    CÃ³digo: {codigo}
    DescripciÃ³n: {descripcion}
    Unidad: {unidad}
    Match Score: {score}

    [Recursos]
    | Tipo | Nombre | Unidad | Cantidad | Confidence |
    |------|--------|--------|----------|------------|
    | ...  | ...    | ...    | ...      | ...        |

    [Warnings]
    | Severity | Message |
    |----------|---------|
    | ...      | ...     |
    ```

- [ ] **8.2** Implementar `src/export/template_exporter.py`
  - FunciÃ³n: `export_per_rubro(results: PipelineResults, template: Path, output: Path)`
  - Crear 1 hoja por rubro
  - Nombre de hoja: `{codigo}` (truncar a 31 chars si excede)
  - Manejo de nombres duplicados: agregar sufijo `_2`, `_3`
  - Usar openpyxl para copiar template y llenar datos

- [ ] **8.3** Implementar fallback mode (global sheets)
  - Si demasiados rubros (>100) o error en per-rubro
  - Usar lÃ³gica v1.0: 5 hojas (Resumen, Rubros, Recursos, Relaciones, Warnings)

- [ ] **8.4** ValidaciÃ³n de nombres de hoja
  - Excel limita nombres a 31 caracteres
  - Caracteres invÃ¡lidos: \ / ? * [ ]
  - FunciÃ³n: `sanitize_sheet_name(name: str) -> str`
  - Truncar + sanitizar + deduplicar

- [ ] **8.5** Configurar export mode
  - CLI flag: `--export-mode per-rubro|global|auto`
  - Auto: per-rubro si <=100 rubros, global si >100
  - Guardar en settings

**Definition of Done:**
- âœ… Template rubro_template.xlsx creado
- âœ… Export per-rubro funcional
- âœ… Fallback global funcional
- âœ… Nombres de hoja sanitizados (<=31 chars)
- âœ… Tests: verificar ambos modos
- âœ… Documentado en SPEC.md

**Artefactos:**
- `data/templates/rubro_template.xlsx`
- `src/export/template_exporter.py`
- `tests/test_export_template.py`
- Excel generado en `data/output/`

---

### FASE 9: TESTS NUEVOS + FIXTURES + VERIFICACIÃ“N

**Objetivo:** Asegurar calidad con tests completos y fixtures.

**Tareas:**

- [ ] **9.1** Crear fixtures
  - `tests/fixtures/pdf_synthetic.pdf` (generado con reportlab)
  - `tests/fixtures/wbs_example.xlsx` (15 rubros de ejemplo)
  - `tests/fixtures/et_mock.json` (estructura simulada)
  - `tests/fixtures/et_mock.md` (markdown de ejemplo)

- [ ] **9.2** Tests de conversiÃ³n
  - `test_docling_converter()` (mock, verificar output)
  - `test_marker_fallback()` (simular fallo Docling)
  - `test_converter_router_auto()` (verificar cascade)

- [ ] **9.3** Tests de normalizaciÃ³n
  - `test_normalize_codigo_variants()` (1.1.1 â†’ 01.01.01)
  - `test_normalize_codigo_ocr_errors()` (O1 â†’ 01, l â†’ 1)
  - `test_normalize_unidad()` (ampliar casos v1.0)

- [ ] **9.4** Tests de matching
  - `test_exact_code_match()` (score=1.0)
  - `test_fuzzy_match()` (score ~0.9)
  - `test_semantic_match()` (embeddings)
  - `test_ambiguous_match()` (score 0.65-0.75)
  - `test_unmatched()` (score <0.65)

- [ ] **9.5** Tests de deduplicaciÃ³n
  - `test_merge_exact_duplicates()` (merge automÃ¡tico)
  - `test_split_conflicts()` (cÃ³digo#A, cÃ³digo#B)
  - `test_code_missing_hash()` (HASH_ID generado)

- [ ] **9.6** Tests de export per-rubro
  - `test_sanitize_sheet_name()` (31 chars, caracteres invÃ¡lidos)
  - `test_export_per_rubro_mode()` (verificar hojas creadas)
  - `test_export_global_fallback()` (>100 rubros)

- [ ] **9.7** Tests de reportes MD
  - `test_run_report_generation()` (estructura correcta)
  - `test_rubro_report_generation()` (snippet truncado)
  - `test_out_json_schema()` (validar con Pydantic)

- [ ] **9.8** Comandos de verificaciÃ³n
  ```bash
  # Tests completos
  pytest tests/ -v --cov=src --cov-report=html

  # Tests rÃ¡pidos (sin embeddings/OCR)
  pytest tests/ -v -m "not slow"

  # Tests de integraciÃ³n
  pytest tests/ -v -m integration

  # Smoke test v1.1
  pytest tests/test_smoke_v1.1.py -v
  ```

**Definition of Done:**
- âœ… Fixtures creados (PDF, WBS, ET.json mock)
- âœ… 30+ tests nuevos implementados
- âœ… Coverage >80% en mÃ³dulos nuevos
- âœ… Comandos de verificaciÃ³n documentados
- âœ… CI/CD compatible (GitHub Actions opcional)

**Artefactos:**
- `tests/fixtures/*.{pdf,xlsx,json,md}`
- `tests/test_convert.py`
- `tests/test_match.py`
- `tests/test_dedupe.py`
- `tests/test_export_template.py`
- `tests/test_report.py`
- `tests/test_smoke_v1.1.py`

---

### FASE 10: CLI/NOTEBOOK + DOCS (README/SPEC)

**Objetivo:** Actualizar interfaces de usuario y documentaciÃ³n completa.

**Tareas:**

- [ ] **10.1** Actualizar CLI en `src/pipeline.py`
  - Agregar argumentos:
    ```bash
    python src/pipeline.py input.pdf \
      --mode advanced \
      --reference wbs.xlsx \
      --export-mode per-rubro \
      --write-artifacts true \
      --match-threshold 0.75 \
      --conversion-strategy auto
    ```
  - Mantener compatibilidad v1.0 (--mode legacy)

- [ ] **10.2** Actualizar notebook `notebooks/pipeline_example.ipynb`
  - Agregar secciÃ³n "Advanced Path (v1.1)"
  - Ejemplos:
    - ConversiÃ³n con Docling
    - Matching WBS â†” ET
    - VisualizaciÃ³n de matches (tabla con Rich)
    - InspecciÃ³n de conflictos
    - Abrir rubros_md para debugging
  - GrÃ¡ficos (opcional): distribuciÃ³n de scores, recursos por tipo

- [ ] **10.3** Crear nuevo notebook `notebooks/advanced_example.ipynb`
  - Foco en features v1.1
  - Ejemplo completo: PDF + WBS â†’ OUT.json
  - AnÃ¡lisis de RUN_REPORT.md
  - ComparaciÃ³n legacy vs advanced

- [ ] **10.4** Actualizar SPEC.md
  - SecciÃ³n nueva: "Advanced Conversion Path"
    - Docling/Marker/PyMuPDF4LLM (features, pros/cons)
    - ConversionResult schema
    - Estrategia auto
  - SecciÃ³n nueva: "Matching SemÃ¡ntico WBSâ†”ET"
    - Multi-stage matching
    - Embeddings (modelo, caching)
    - Scoring (thresholds, penalizaciones)
    - MatchResult schema
  - SecciÃ³n nueva: "Dedup & Conflicts"
    - 3 casos: exact, conflict, code_missing
    - Estrategias merge/split/hash
  - SecciÃ³n nueva: "Artifacts v1.1"
    - ET.md, ET.json, OUTLINE.md, OUT.json
    - RUN_REPORT.md, rubros_md/
  - SecciÃ³n nueva: "Excel Template Mode"
    - Per-rubro vs global
    - SanitizaciÃ³n de nombres de hoja

- [ ] **10.5** Crear ARCHITECTURE.md
  - Diagrama de mÃ³dulos (ASCII art)
  - Dataflow: PDF â†’ ConversiÃ³n â†’ Outline â†’ Match â†’ Dedupe â†’ Reportes â†’ Excel
  - Legacy vs Advanced path (comparaciÃ³n)
  - Modelos Pydantic (lista completa)

- [ ] **10.6** Actualizar README.md
  - Agregar "Quick Start v1.1"
  - Features nuevas destacadas
  - Ejemplos de uso advanced mode
  - Ãrbol de carpetas actualizado

- [ ] **10.7** Actualizar QUICKSTART.md
  - Comando rÃ¡pido v1.1:
    ```bash
    python src/pipeline.py input.pdf \
      --mode advanced \
      --reference wbs.xlsx
    ```

**Definition of Done:**
- âœ… CLI con flags v1.1 funcional
- âœ… Notebook actualizado con ejemplos advanced
- âœ… SPEC.md con 5 secciones nuevas
- âœ… ARCHITECTURE.md creado con diagramas
- âœ… README/QUICKSTART actualizados
- âœ… DocumentaciÃ³n revisada y consistente

**Artefactos:**
- `src/pipeline.py` (CLI actualizado)
- `notebooks/pipeline_example.ipynb` (actualizado)
- `notebooks/advanced_example.ipynb` (nuevo)
- `ARCHITECTURE.md` (nuevo)
- `SPEC.md` (actualizado)
- `README.md` (actualizado)
- `QUICKSTART.md` (actualizado)

---

## ðŸ“Š RESUMEN DE ENTREGABLES FINALES

| Artefacto | UbicaciÃ³n | DescripciÃ³n |
|-----------|-----------|-------------|
| **ET.md** | `data/artifacts/` | Markdown fiel al PDF (inspecciÃ³n humana) |
| **ET.json** | `data/artifacts/` | Estructura del documento (secciones, tablas, bloques) |
| **OUTLINE.md** | `data/artifacts/` | JerarquÃ­a PÃ¡gina â†’ SecciÃ³n â†’ Rubro |
| **OUT.json** | `data/artifacts/` | JSON puente final (matches + recursos + warnings) |
| **RUN_REPORT.md** | `data/artifacts/` | Reporte de ejecuciÃ³n (resumen + conflictos) |
| **rubros_md/** | `data/artifacts/rubros_md/` | 1 archivo MD por rubro (evidencia + recursos) |
| **resultado.xlsx** | `data/output/` | Excel (per-rubro o global) |

---

## ðŸŽ¯ MÃ‰TRICAS DE Ã‰XITO

| MÃ©trica | Target | ValidaciÃ³n |
|---------|--------|------------|
| **ConversiÃ³n exitosa** | >95% PDFs | Test con 20 PDFs reales |
| **Match accuracy** | >90% rubros | ComparaciÃ³n manual 50 rubros |
| **Dedup precision** | 100% merge exactos | Test unitario |
| **Conflict detection** | >95% conflictos reales | RevisiÃ³n manual |
| **Test coverage** | >80% mÃ³dulos nuevos | pytest-cov |
| **Performance** | <5min por PDF (50 pÃ¡ginas) | Benchmark |
| **Usabilidad** | CLI + Notebook ejecutable sin errores | Smoke test |

---

## ðŸš¨ RIESGOS Y MITIGACIONES

| Riesgo | Impacto | MitigaciÃ³n |
|--------|---------|------------|
| Docling no instala en Windows | Alto | Fallback a Marker + PyMuPDF4LLM |
| Embeddings muy lentos | Medio | Cache + FAISS + batch processing |
| OCR con bajo confidence | Alto | MÃºltiples conversores + threshold ajustable |
| Nombres de hoja Excel >31 chars | Bajo | SanitizaciÃ³n automÃ¡tica + truncado |
| Conflictos no detectados | Medio | Tests exhaustivos + revisiÃ³n manual |
| Template Excel corrupto | Bajo | ValidaciÃ³n + fallback a global mode |

---

## ðŸ“… ESTIMACIÃ“N DE TIEMPO

| Fase | Complejidad | Tiempo estimado | Dependencias |
|------|-------------|-----------------|--------------|
| Fase 0 | Baja | 2h | - |
| Fase 1 | Alta | 8h | Fase 0 |
| Fase 2 | Media | 4h | Fase 1 |
| Fase 3 | Baja | 3h | Fase 0 |
| Fase 4 | Alta | 10h | Fase 3 |
| Fase 5 | Media | 6h | Fase 1, 4 |
| Fase 6 | Media | 5h | Fase 4 |
| Fase 7 | Media | 6h | Fase 6 |
| Fase 8 | Media | 5h | Fase 7 |
| Fase 9 | Media | 8h | Todas |
| Fase 10 | Baja | 4h | Fase 9 |
| **TOTAL** | - | **~60h** | - |

---

## âœ… CHECKLIST DE ACEPTACIÃ“N

### Funcionalidades Core v1.1

- [ ] ConversiÃ³n estructurada con Docling/Marker/PyMuPDF4LLM
- [ ] GeneraciÃ³n de ET.md + ET.json + OUTLINE.md
- [ ] Carga de WBS reference (XLSX/CSV)
- [ ] Matching semÃ¡ntico WBS â†” ET (embeddings + fuzzy)
- [ ] ExtracciÃ³n de recursos layout-aware desde tablas
- [ ] ResoluciÃ³n de duplicados (merge/split/hash)
- [ ] GeneraciÃ³n de OUT.json + RUN_REPORT.md + rubros_md/
- [ ] Export Excel per-rubro con template
- [ ] Export Excel global (fallback)
- [ ] CLI con flags v1.1
- [ ] Notebook con ejemplos advanced

### Calidad

- [ ] Tests >30 nuevos (conversiÃ³n, match, dedupe, export)
- [ ] Coverage >80% en mÃ³dulos nuevos
- [ ] Smoke test v1.1 passing
- [ ] Fixtures creados (PDF, WBS, ET.json)
- [ ] DocumentaciÃ³n completa (SPEC, ARCHITECTURE, README)

### Performance

- [ ] Procesamiento <5min por PDF de 50 pÃ¡ginas
- [ ] Cache de embeddings funcional
- [ ] No memory leaks en batch processing

### Usabilidad

- [ ] CLI ejecutable sin errores
- [ ] Notebook ejecutable sin errores
- [ ] Reportes MD legibles (<=2 pantallas)
- [ ] Excel abre sin warnings

---

**FIN DEL PLAN DE ACCIÃ“N v1.1**

---

## ðŸš€ PRÃ“XIMO PASO

**Ejecutar Fase 0:** AuditorÃ­a + Setup inicial

```bash
# 1. Crear estructura de carpetas
mkdir -p src/{convert,outline,match,dedupe,report,config}
mkdir -p data/{templates,artifacts/rubros_md}
mkdir -p tests/fixtures

# 2. Instalar dependencias
pip install -r requirements-full.txt

# 3. Verificar estado
pytest tests/test_smoke.py -v
```
